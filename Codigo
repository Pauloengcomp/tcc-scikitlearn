!pip install pysus
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

from pysus.online_data import SIM
arquivos = SIM.download(groups=["cid10"],states='BA', years=2023)
arquivos

import os
df = arquivos.to_dataframe()
print(df.shape)
df.head()

modelo_rf = RandomForestClassifier(
    n_estimators=100,         # Número de árvores na floresta
    max_depth=10,             # Profundidade máxima das árvores
    class_weight='balanced',  # Balanceamento automático das classes
    random_state=42,          # Reprodutibilidade
    n_jobs=-1                 # Utilizar todos os núcleos disponíveis
)

X_train = X_train.fillna(0)
X_test = X_test.fillna(0)

X = X.fillna(-1)  # ou outro valor para nulos

# Codificar variáveis categóricas
X = pd.get_dummies(X)

# Codificar y (CAUSABAS) como números (para o modelo)
le = LabelEncoder()
y_encoded = le.fit_transform(y)

df_sample = df.sample(frac=0.1, random_state=42)  # 10% da base

X = df_sample[['IDADE', 'SEXO', 'RACACOR', 'ESC', 'LOCOCOR']]
y = df_sample['CAUSABAS']

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in ['SEXO', 'RACACOR', 'ESC', 'LOCOCOR']:
    X[col] = le.fit_transform(X[col].astype(str))

limiar = 10  # mínimo de ocorrências para manter classe
frequentes = y.value_counts()[y.value_counts() >= limiar].index

y_agrupado = y.where(y.isin(frequentes), other='OUTROS')

print(y_agrupado.value_counts())

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y_agrupado, test_size=0.2, random_state=42, stratify=y_agrupado
)

from sklearn.tree import DecisionTreeClassifier

modelo = DecisionTreeClassifier(max_depth=10, random_state=42)
modelo.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

y_pred = modelo.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print(f"Acurácia: {acc:.2f}")

print("Relatório de Classificação:")
print(classification_report(y_test, y_pred))

# Criar a coluna de capítulo CID
y_capitulo = y.str[0]

print(y_capitulo.value_counts())


# Função para criar faixas etárias
def faixa_etaria(idade):
    if idade <= 1:
        return 'Bebê'
    elif idade <= 14:
        return 'Criança'
    elif idade <= 49:
        return 'Adulto Jovem'
    elif idade <= 64:
        return 'Meia-Idade'
    else:
        return 'Idoso'

X = df_sample[['IDADE', 'SEXO', 'RACACOR', 'ESC', 'LOCOCOR']].copy()

# Agora pode seguir normalmente:
X['IDADE'] = pd.to_numeric(X['IDADE'], errors='coerce')
X['IDADE'] = X['IDADE'].fillna(X['IDADE'].median())
X['FAIXA_ETARIA'] = X['IDADE'].apply(faixa_etaria)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in ['SEXO', 'RACACOR', 'ESC', 'LOCOCOR', 'FAIXA_ETARIA']:
    X[col] = le.fit_transform(X[col].astype(str))

# 1. Contar as classes
vc = y_capitulo.value_counts()

# 2. Manter apenas capítulos com 2 ou mais ocorrências
capitulos_validos = vc[vc >= 2].index

# 3. Filtrar
mask = y_capitulo.isin(capitulos_validos)
X = X[mask]
y_capitulo = y_capitulo[mask]

# 4. Agora fazer o train_test_split com stratify
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y_capitulo, test_size=0.2, random_state=42, stratify=y_capitulo
)

from sklearn.tree import DecisionTreeClassifier

modelo = DecisionTreeClassifier(
    max_depth=10,              # limita a profundidade para evitar overfitting
    min_samples_split=10,      # mínimo de amostras para dividir um nó
    min_samples_leaf=5,        # mínimo de amostras em cada folha
    class_weight='balanced',   # balanceia as classes automaticamente
    random_state=42
)

modelo.fit(X_train, y_train)

y_pred = modelo.predict(X_test)

from sklearn.metrics import accuracy_score, f1_score, classification_report

acc = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')

print(f"Acurácia: {acc:.2f}")
print(f"F1 Macro: {f1_macro:.2f}")

print("Relatório de Classificação:")
print(classification_report(y_test, y_pred))

pip install imblearn

# Preencher valores ausentes
X_train = X_train.fillna(0)

# Converter todas as colunas para float
X_train = X_train.astype(float)

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train, y_train)

print(f"Antes: {X_train.shape}, Depois: {X_res.shape}")

from sklearn.tree import DecisionTreeClassifier

modelo_smote = DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight='balanced',
    random_state=42
)

modelo_smote.fit(X_res, y_res)

from sklearn.metrics import accuracy_score, f1_score, classification_report

y_pred_smote = modelo_smote.predict(X_test)

acc_smote = accuracy_score(y_test, y_pred_smote)
f1_macro_smote = f1_score(y_test, y_pred_smote, average='macro')

print(f"[SMOTE] Acurácia: {acc_smote:.2f}")
print(f"[SMOTE] F1 Macro: {f1_macro_smote:.2f}")
print("Relatório SMOTE:")
print(classification_report(y_test, y_pred_smote))

def agrupar_supergrupo(codigo):
    if codigo in ['A', 'B']:
        return 'Doenças Infecciosas'
    elif codigo in ['C', 'D']:
        return 'Neoplasias'
    elif codigo in ['I', 'J', 'K']:
        return 'Doenças Crônicas'
    elif codigo in ['R', 'X', 'Y']:
        return 'Causas Externas'
    else:
        return 'Outros'

y_supergrupo = y_capitulo.apply(agrupar_supergrupo)

from sklearn.model_selection import train_test_split

X_train_sg, X_test_sg, y_train_sg, y_test_sg = train_test_split(
    X, y_supergrupo, test_size=0.2, random_state=42, stratify=y_supergrupo
)

modelo_sg = DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight='balanced',
    random_state=42
)

modelo_sg.fit(X_train_sg, y_train_sg)

y_pred_sg = modelo_sg.predict(X_test_sg)

acc_sg = accuracy_score(y_test_sg, y_pred_sg)
f1_macro_sg = f1_score(y_test_sg, y_pred_sg, average='macro')

print(f"[Supergrupo] Acurácia: {acc_sg:.2f}")
print(f"[Supergrupo] F1 Macro: {f1_macro_sg:.2f}")
print("Relatório Supergrupo:")
print(classification_report(y_test_sg, y_pred_sg))
